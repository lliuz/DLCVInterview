### 技巧

#### 项目详细介绍

1. 不要一上来就用了什么网络，要**有前因后果有条理的表述**，从 insight 到 motivation 到 method 到实验设计到结论逻辑性的分析到反思有什么可以改进的点。
2. 要**大方承认工作中的不足，可以接受面试官的质疑**
3. 在面对不会的问题时，是否有积极的思考，而不是遇到不会的问题就直接放弃，**哪怕回答不完全正确都没有问题**。

### 论文介绍

#### ARFlow

insight: 早前无监督或者自监督的光流估计都只用很少的数据扩增方法，但监督学习里却使用很多。

motivation: 因为自监督学习靠的是对比重投影误差，我认为造成 heavy augmentation 在无监督中不常见的原因是无监督或者自监督学习的损失函数在扩增数据上不鲁棒，因此我设计了一种新的学习框架，叫做类比学习，解决这个问题。

method: 

conclusion: 方法很简单，所以做了非常详细的对比试验，此外，现在看在分类和 nlp 上已经有比较多类似的工作了，

#### UnRigidFlow

insight: 自监督学习双目深度和光流这两个问题的机理是类似的，但是双目深度看的是左右帧，光流看的是前后帧，而且双目是 3D 的角度看问题，光流是 2D 的角度，这里面存在一些信息互补。

motivation: 能否通过这两个子任务进行竞争与合作，来互相促进。

methods: PnP - RANSAC

conclusion: 因为 PnP-RANSAC 是一个类似于最小二乘的拟合，所以结果会在全局上更加统一，但是也是有缺陷的。

> #### Q: PnP 原理
>
> PnP 解决的是n 个 3D 空间点以及它们的投影位置时,如何估计相机所在的位姿，最少只需要三个点对即可求解(P3P)。
>
> > PnP: t1 世界坐标系中的点投影到 t0 相机坐标系上的位姿关系，ICP 是 t1 世界坐标系到 t0 世界坐标系的位姿关系，对极几何是 t0 左图到 t0 右图的位置关系。
>
> PnP 的本质上就是解一个最小化误差函数的最小二乘问题，
>
> DLT: 取六个点对，每一个 3D 点到归一化平面的映射给出两个约束，去求解 RT 矩阵中的 12 个未知数。
>
> P3P: 取 3 对 3D/2D 匹配点，解出四种可能的姿态。将世界坐标系下的 ABC 三点和图像坐标系下的 abc 三点匹配，三个点之间三维长度和二维角度已知，通过余弦定理可以求出 A，B，C 在相机参考系中的坐标，建立一个二元二次方程组，就可以求得当前相机位姿(四个解)，再第四个点去验证即可。
>
> EPnP: 取 4 对不共面的（对于共面的情况只需要3对）3D-2D匹配点。通过n个3D点在相机平面的投影关系，以及与这四个控制点的权重关系，构建一个12*12方阵，求得其零空间特征向量，可以得到虚拟控制点的相机平面坐标，然后使用 POSIT 算法即可求出相机位姿。
>
> 通常在用 EPnP 求得四对点下的封闭解后，可以将该解作为非线性优化的初值，优化提高精度。
>
> #### Q: RANSAC 原理
>
> RANSAC 通过反复数据中的随机子集来减少外点对模型参数估计的影响。
>
> 用下述方法进行优化：
>
> 1. 随机采样子集，被选取的子集被假设为内点，利用当前采样得到的子集估计模型参数；
> 2. 用估计的模型去测试所有的未采样到的数据，如果某个点适用于估计的模型，认为它也是内点；
> 3. 统计内点个数，返回1步，重复多次取内点个数最多的模型；
> 4. (可选) 用新旧内点重新估计模型；

#### n-bit QNN

提出针对 QNN 训练的损失函数，在反向传播算法中重建梯度函数，克服了训练 QNN 时的梯度消失。

全精度网络 -> 权重归一化 -> 对数量化(与之对应的叫做线性量化)到 [±2^0, ±2^-1, ..., ±2^-n, 0]；

提出用 shift 操作代替乘法操作，因为 FPGA 实现更快。提出的移位向量处理单元，SVPE 比传统的 VPE 快 2.9 倍，另外因为 shift 操作不消耗 FPGA 的 DSP，平均能量消耗减少了 68.7%。

#### PoseConvGRU

#### ObjectFusion

### 项目简介

#### 东芝流水线检测

background: 手工流水线的操作是一站一站级联的，通过设定好一个周期来滑动流水线，如果在流水线动了还没操作完可以按急停会有个额外的20秒时间处理。这也就有了一个短板效应，只有当最慢的一站完成了才能进行下一个工件的处理，所以 line balance 很重要，也就需要去知道每个工人什么时候完成操作，但是又不能影响工人，比如让工人增加任何额外的操作。

motivation: 传统的工厂会通过定时派人抽查的形式评估每个人完成每个操作的时间，但是这样要额外的人力，而且如果去现场监督的话，会影响工作状态，所以希望有一套智能操作追踪系统。

methods: 另外因为是落地的项目，需要成本控制，所以就直接用了已有的摄像头和甲方自研的工控机(算力很差，没有gpu)。所以肯定不能跑实时的 action 网络，我们采取的方案是检测关键帧 + 跟踪 + 根据轨迹的行为分类网络 + 逻辑判断。逻辑判断部分一开始流水线运动检测不能做到100%准确，在逻辑代码的第一步就出现了问题，后面直接通过在流水线上帖标志物 aruco 解决了这个问题。

conclusion: 尽管现在一直在推全自动化流水线，但是很多业务实际上还是离不开手工流水线的。如果做到极致的话，理论上是可以做到完全智能的 line balance的，甚至可以做到技能评估。

future: 一个是这个主要还是算力限制，另外我觉得项目目的没有制定的特别合理，一开始的目标是做到完全自主的流水线控制，所以有实时性要求，但其实是做不到的，所以一开始就应该设计上私有云而不是端上处理，上云的话就可以不用局部识别的方案，毕竟操作过程里很多时候手是会遮挡的，跟踪非常困难。

> #### Q: 二分图匹配算法
>
> $$O(n^3)$$ <https://blog.csdn.net/u014754127/article/details/78086014> 求解任务分配(二分图匹配)问题的组合优化算法，
>
> 和最大流问题类似，其核心也是找增广路径，基本模式是：
>
> ```c++
> 初始时最大匹配为空
> while 找得到增广路径 do 
>      把增广路径加入到最大匹配中去
> ```
>
> [具体实现](https://blog.csdn.net/u011837761/article/details/52058703)：
>
> 1. 找出每一行中值最小的元素，然后把该行所有元素都减去这一最小值
> 2. 找出每一列中值最小的元素，然后把该列所有元素都减去这一最小值
> 3. 用尽量少的横线或竖线覆盖矩阵中的所有0
> 4. 从上一步中未被覆盖的元素中找到最小值，然后把这些元素都减去最这一小值、给直线交叉点的元素加上这一最小值
> 5. 重复Step-3和Step-4，直到所有任务都被分配
>
> #### Q: 卡尔曼滤波解释
>
> 即把模型算出来的值和观测的值进行加权平均。
>
> **新的最佳估计**是基于 **原最佳估计** 和 **当前观测** 融合后得到的预测。
>
> **新的不确定性**是基于 **原不确定性** 和 **当前观测的不确定性** 融合得到的预测。
>
> 这个项目里用的一阶线性模型，也就是匀速变化。状态量为bbox的中心点和长宽以及一阶导。把每帧的框组用匈牙利算法先匹配，再通过迭代更新位置和不确定性。
>
> #### Q: Sort 的改进
>
> 
>
> #### Q: TAL 方法的简述
>
> 

#### 华为手势识别

motivation: 融合 MIC 发出的超声和屏下摄像头的视频，做到实时的悬浮手势识别。在 Mate 20 pro，麒麟 980 上，TFlite 原生支持 NNAPI 调用 NPU 进行计算。

methods: 因为算力有限，采用的技术方案和东芝的类似，二阶段动态手势识别方案，先经过手部运动检测网络判断是否有手的运动并预估手的位置，再输入动态手势网络进行分类。与东芝的项目不同点在于：1. 第一阶段没有跑 detection 的网络，而是设计了一个双分支的全卷积网络，分类分支对 7x7 的 map 作 Global Average Pooling 出画面是否有且只有一个应该被 focus 的手(三分类)，另一个分支输出同样的 7x7 的 map，每个 map 为 anchor 到手中心点的像素偏移。2. 第二阶段没有时间的回归，直接用了一个魔改的 TRN 做分类 (一阶段自适应间隔的采样 8 帧窗口 300ms ~ 1000ms)。

future: 整个框架我觉得还是挺优雅的，继续优化的话就考虑 latency 的优化和逻辑代码的优化了。

> Q: TF 计算图原理
>
> Q: TFLite 做了哪些事情
>
> Q: TRN 的结构以及简化

#### 咪咕健身指导

motivation: 一两年前在头条出现过一个跳舞的游戏，就是在一些节点要和动画小人的姿势一致。我们这个项目实际比头条这个游戏早一年，而且要更难，因为我们这个对比的时间是不一定的，而头条的对比时间是确定的。另外健身评估实际上是一个 3D 的评估，有些角度从 2D 上看和 3D 是完全不一样的，所以要用 3D pose 方法。

methods: 比较 low， 提取 2D 关键点,KD tree 直接映射到 3D，手工构建 pose 特征，通过逻辑代码，在关键帧的时刻与教练模型进行特征比对。

future: 首先是更准确的单目 3D pose 方法，但是这个总归是一个病态的问题，我个人觉得最好还是用 kinect 之类的传感器，手机的双目没啥用，基线太短了，tof 现在也不太准。一方面是优化关键帧检测的策略，通过视频网络或者骨架的方式+逻辑代码的方式检测出是否是关键帧。另一方面，度量学习打分替代手工特征。

> Q: 深度传感器介绍
>
> Q: KD-Tree 原理，k 值选取

