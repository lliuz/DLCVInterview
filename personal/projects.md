### 技巧

#### 项目详细介绍

1. 不要一上来就用了什么网络，要**有前因后果有条理的表述**，从 insight 到 motivation 到 method 到实验设计到结论逻辑性的分析到反思有什么可以改进的点。
2. 要**大方承认工作中的不足，可以接受面试官的质疑**
3. 在面对不会的问题时，是否有积极的思考，而不是遇到不会的问题就直接放弃，**哪怕回答不完全正确都没有问题**。

### 论文介绍

#### ARFlow

insight: 早前无监督或者自监督的光流估计都只用很少的数据扩增方法，但监督学习里却使用很多。

motivation: 因为自监督学习靠的是对比重投影误差，我认为造成 heavy augmentation 在无监督中不常见的原因是无监督或者自监督学习的损失函数在扩增数据上不鲁棒，因此我设计了一种新的学习框架，叫做类比学习，解决这个问题。

method: 

conclusion: 方法很简单，所以做了非常详细的对比试验，此外，现在看在分类和 nlp 上已经有比较多类似的工作了，

#### UnRigidFlow

insight: 自监督学习双目深度和光流这两个问题的机理是类似的，但是双目深度看的是左右帧，光流看的是前后帧，而且双目是 3D 的角度看问题，光流是 2D 的角度，这里面存在一些信息互补。

motivation: 能否通过这两个子任务进行竞争与合作，来互相促进。

methods: PnP - RANSAC

conclusion: 因为 PnP-RANSAC 是一个类似于最小二乘的拟合，所以结果会在全局上更加统一，但是也是有缺陷的。

> Q: PnP 原理
>
> Q: RANSAC 原理

#### n-bit QNN

#### PoseConvGRU

#### ObjectFusion

### 项目简介

#### 东芝流水线检测

background: 手工流水线的操作是一站一站级联的，通过设定好一个周期来滑动流水线，如果在流水线动了还没操作完可以按急停会有个额外的20秒时间处理。这也就有了一个短板效应，只有当最慢的一站完成了才能进行下一个工件的处理，所以 line balance 很重要，也就需要去知道每个工人什么时候完成操作，但是又不能影响工人，比如让工人增加任何额外的操作。

motivation: 传统的工厂会通过定时派人抽查的形式评估每个人完成每个操作的时间，但是这样要额外的人力，而且如果去现场监督的话，会影响工作状态，所以希望有一套智能操作追踪系统。

methods: 另外因为是落地的项目，需要成本控制，所以就直接用了已有的摄像头和甲方自研的工控机(算力很差，没有gpu)。所以肯定不能跑实时的 action 网络，我们采取的方案是检测关键帧 + 跟踪 + 根据轨迹的行为分类网络 + 逻辑判断。逻辑判断部分一开始流水线运动检测不能做到100%准确，在逻辑代码的第一步就出现了问题，后面直接通过在流水线上帖标志物 aruco 解决了这个问题。

conclusion: 尽管现在一直在推全自动化流水线，但是很多业务实际上还是离不开手工流水线的。如果做到极致的话，理论上是可以做到完全智能的 line balance的，甚至可以做到技能评估。

future: 一个是这个主要还是算力限制，另外我觉得项目目的没有制定的特别合理，一开始的目标是做到完全自主的流水线控制，所以有实时性要求，但其实是做不到的，所以一开始就应该设计上私有云而不是端上处理，上云的话就可以不用局部识别的方案，毕竟操作过程里很多时候手是会遮挡的，跟踪非常困难。

> Q: 二分图匹配算法
>
> Q: Sort 的改进
>
> Q: TAL 方法的简述

#### 华为手势识别

motivation: 融合 MIC 发出的超声和屏下摄像头的视频，做到实时的悬浮手势识别。在 Mate 20 pro，麒麟 980 上，TFlite 原生支持 NNAPI 调用 NPU 进行计算。

methods: 因为算力有限，采用的技术方案和东芝的类似，二阶段动态手势识别方案，先经过手部运动检测网络判断是否有手的运动并预估手的位置，再输入动态手势网络进行分类。与东芝的项目不同点在于：1. 第一阶段没有跑 detection 的网络，而是设计了一个双分支的全卷积网络，分类分支对 7x7 的 map 作 Global Average Pooling 出画面是否有且只有一个应该被 focus 的手(三分类)，另一个分支输出同样的 7x7 的 map，每个 map 为 anchor 到手中心点的像素偏移。2. 第二阶段没有时间的回归，直接用了一个魔改的 TRN 做分类 (一阶段自适应间隔的采样 8 帧窗口 300ms ~ 1000ms)。

future: 整个框架我觉得还是挺优雅的，继续优化的话就考虑 latency 的优化和逻辑代码的优化了。

> Q: TF 计算图原理
>
> Q: TFLite 做了哪些事情
>
> Q: TRN 的结构以及简化

#### 咪咕健身指导

motivation: 一两年前在头条出现过一个跳舞的游戏，就是在一些节点要和动画小人的姿势一致。我们这个项目实际比头条这个游戏早一年，而且要更难，因为我们这个对比的时间是不一定的，而头条的对比时间是确定的。另外健身评估实际上是一个 3D 的评估，有些角度从 2D 上看和 3D 是完全不一样的，所以要用 3D pose 方法。

methods: 比较 low， 提取 2D 关键点,KD tree 直接映射到 3D，手工构建 pose 特征，通过逻辑代码，在关键帧的时刻与教练模型进行特征比对。

future: 首先是更准确的单目 3D pose 方法，但是这个总归是一个病态的问题，我个人觉得最好还是用 kinect 之类的传感器，手机的双目没啥用，基线太短了，tof 现在也不太准。一方面是优化关键帧检测的策略，通过视频网络或者骨架的方式+逻辑代码的方式检测出是否是关键帧。另一方面，度量学习打分替代手工特征。

> Q: 深度传感器介绍
>
> Q: KD-Tree 原理，k 值选取

